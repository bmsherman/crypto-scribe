
\documentclass[10pt]{article}
\usepackage{amsfonts,amsthm,amsmath,amssymb}
\usepackage{array}
\usepackage{epsfig}
\usepackage[
  margin=1.5cm,
  includefoot,
  footskip=30pt,
]{geometry}

%%% YOUR NAMES GO HERE %%%
\newcommand{\scribes}{Eric Atkinson, Ben Sherman}
%%% LECTURE NUMBER %%%
\newcommand{\lecnumber}{24}
%%% TITLE OF THE LECTURE %%%
\newcommand{\lectitle}{Cryptography when secrecy is hard to find (leakage resistance)}
%%% DATE OF THE LECTURE %%%
\newcommand{\thedate}{May 4, 2016}

  \usepackage [ n,
advantage , operators , sets , adversary , landau , probability , notions , logic ,
ff, mm,
primitives , events , complexity , asymptotics , keys
]{ cryptocode}
   
   

\newcommand{\bit}{\{0,1\}}
\newcommand{\unif}[1]{\mathcal{U}\left[{#1}\right]}
\newcommand{\Prob}[1]{\text{Pr}\left[ {#1} \right]}
\newcommand{\given}{\ |\ }
\newcommand{\suchthat}{\given}
\newcommand{\nat}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bool}{\mathbb{B}}
\newcommand{\cat}{\ ||\ }
\newcommand{\then}{\ ;\ }
\newcommand{\keys}{\mathcal{K}}

\begin{document}
\input{scribe-template-preamble.tex}

\handout{6.875J/18.425J Cryptography and Cryptanalysis}
{\thedate}
{Instructor: Shafi Goldwasser}
{Scribes: \scribes}
{Lecture \lecnumber: \lectitle}
{\lecnumber}

%%%% body goes in here %%%%
\section{Introduction to side-channel attacks}

So far in the class, the cryptographic protocols and constructions that we have considered have used the following assumptions:
\begin{itemize}
\item Algorithms are public.
\item Private keys are perfectly secret and random.
\item Cryptographic computations are opaque to an adversary.
\end{itemize}

These common assumptions provide a rich theory based on reductionist security proofs from computational assumptions to secure primitives. And so far in this class, we have explored a variety of computational notions within this framework, and found some surprising abilities (such as public key cryptography, homomorphic encryption, etc.).

However, the above assumptions do not hold in many real-life settings, because computations ``leak.''
For instance, we assume a secret key that is stored on one's computer cannot be observed by an adversary, while this is not necessarily the case.

When computations run on a computer, they consume power, and emit noise and radiation. By measuring how much time the computation takes, or how much heat the computer generates (such as by detecting changes in temperature in the nearby environment), it is possible information about  secret keys used in cryptographic protocols. 

It's possible to translate physical observations into attacks on the security of cryptographic schemes. Our proofs in the class so far have not taken into account these considerations. Attacks include:

\begin{itemize}
\item \emph{Cold boot attacks} are attacks on computers which are not running. If a computer is inspected not longer after it is shut off, the memory may still retain information, and so it is possible to recover secret keys. Contents in RAM decay slowly after losing power, and may last for several minutes.
\item Garfinkle \cite{garfinkel2003} looked at \emph{erased hard disks} and was able to recover lots of forensic information.
\item \emph{Shared sources of randomness}: Often, there is reuse of secret keys across different cryptographic applications. Using access to many cryptographic public keys, where the private keys are correlated with each other (due to a shared source of randomness), it may be possible to defeat cryptographic security.
\item \emph{Timing attacks} glean information by measuring how much time a computation takes. For instance, one can, by observing how much time an RSA signing scheme takes, learn about the RSA exponent (given that signing is performed via repeated squaring with the exponent, and some exponents will take longer than others).
\item \emph{Power consumption attacks} measure the power consumed while performing cryptographic operations.
\end{itemize}

There are countermeasures meant to prevent side-channel attacks such as those listed above. There are both hardware and software countermeasures. In hardware, it is possible to shield components to make it difficult to measure the emission of radiation or heat. In software, it is possible to try to fix the timing of cryptographic operations, to use oblivious RAM, and to use various other heuristics to prevent leakage of information through side-channels.

Can we use more \emph{theory} at design time to battle reality? Can we do cryptography assuming \emph{no} secrecy? Maybe we don't need secret keys at all. Maybe everything can be public, and we can still do public key encryption, secure computation, and so on. \emph{Obfuscation} attempts to answer this question (though it has seemingly yet to succeed). In this lecture, we can't do away with all secrecy, but can reduce the amount of secrecy required.

Approaching side-channel attacks from a theoretical angle, we explicitly model side-channel attacks. We can then try to build modified schemes which are secure with respect to this model, and even try to construct general compilers for protocols secure against these models from protocols which are secure under classical cryptographic assumptions.

Work modeling side-channel attacks is highly technical, so this lecture provides only a glimpse. So far, the results have questionable benefit. Schemes often only provide security against a fixed fraction of leakage. So a scheme may be secure against leaking 90\% of the secret key, but to be secure against 95\% leakage, a completely different scheme may be required.

We now present a mathematical model side-channel attacks (computation time, power, etc.). Later, we will discuss the addition of secure hardware assumptions to cryptographic assumptions. The goal will be to use the same computational assumptions as before, and to minimize the use of secure hardware.

There are a variety of ways to model side-channel attacks. All of the models generally maintain the notion of a PPT adversary $A$. In addition to $A$'s computational abilities, $A$ is allowed to make measurements $L(\cdot)$ on the internal state of a computation. Models differ in what restrictions are imposed on the measurement function $L$:

\begin{itemize}
\item What does $L$ really have access to? Possible choices include the entire state of the computation, or only a certain amount of internal state, or perhaps only contents of the cache. In the \emph{memory leakage} (ML) class of models, we have \emph{global measurements}, where $L$ applies to the entire memory. In contrast, with the \emph{only computation} (OC) class of models, we have only \emph{local measurements}, so $L$ can only be applied to memory that is being used in the current computation step.
\item What complexity class does $L$ come from? $L$ may be required to be a polynomial-time algorithm or representable by a ``low-depth'' circuit.
\item How many measurements can $L$ make? In \emph{bounded leakage} models, it can only measure once, or a limited number of times. In \emph{continual leakage} models, there is no bound on the number of times that measurements can be made. However, it is possible to prevent information leakage by erasing memory contents. For instance, a scheme secure against a continual leakage model might use the same public key, but keep changing secret keys, and erasing previous ones, so that an adversary cannot fully determine a single secret key.
\item When is $L$ chosen? Before or after the public key is chosen?
\item Is there noise in the measurement of $L$? For instance, it could be modeled as a random variable which is only biased towards the actual internal state.
\end{itemize}

\section{Bounded memory leakage (ML)}

In this section, we will consider how to design a public key encryption scheme which is secure with respect to the bounded memory leakage (ML) model, where the adversary can make partial measurements a bounded number of times.

The idea in this model is that the adversary can recover ``noisy''' keys. Suppose you're using RSA, and you have stored in memory the decryption exponent $d$ (where $d e = 1 \mod \varphi(n)$). The adversary can't see $d$ exactly, but can see a noisy version of $d$. 

We update the notion of semantic security to take into account the adversary's new capabilities. We're going to change it as follows: A scheme is semantically secure against a $\lambda$-memory attack if for any leakage function $L(\cdot)$ which can leak some fraction of the bits of the secret key (depending on the parameter $\lambda$), the adversary is still unable to distinguish encryptions (see the game in figure \ref{lambdasec}).

Let $\keys_S = \bit^{n_{SK}}$ be the set of private keys, represented as bitstrings of length $n_SK$. We require for the measurement function $L : \keys_S \to \bit^n$ can only determine some number $\lambda(n_{SK})$ of the bits, that is, $n < \lambda(n_{SK})$. This means that it is impossible for $L$ to uniquely determine the secret key. In fact, this requirement is just as strong as the requirement that there must be some entropy remaining in the secret key when conditioned on the observation of $L$.

\begin{figure}
\begin{center}
\pseudocode{%
\textbf{Adversary} \< \< \textbf{Challenger} \\[0.1\baselineskip ][\hline ]
\<\< \\[-0.5\baselineskip ] 
\<\< (sk, pk) \gets \gen  \\
\< \sendmessageleft*{pk} \< \\
\< \sendmessageright*{L(\cdot)} \< \\
\< \sendmessageleft*{L(sk)} \< \\
\< \sendmessageright*{m_0, m_1} \< \\
\< \sendmessageleft*{c = \enc(pk, m_b)} \<  b \sample \bit \\
\< \sendmessageright*{b'} \< \\
\< \text{Adversary wins when $b = b'$} \<}
 \end{center}
 \caption{Semantic security game for public-key encryption with side-channels.}
 \label{lambdasec}
 \end{figure}

Most contemporary protocols are not very secure with respect to this model. RSA is theoretically secure with up to 50\% leakage, but practically found insecure with as little as 25\% leakage. AES is insecure against 85\% leakage.

It is in fact possible to create public key encryption secure against memory leakage attacks with an arbitrarily large fraction of leakage:

\begin{theorem}
For every $\varepsilon > 0$, there exists a public key encryption scheme that can tolerate $\lambda(n_{SK}) = (1 - \varepsilon)n_{SK}$ leakage attacks.
\end{theorem}
Constructions of such schemes use either lattice problems, Diffie-Hellman decisional intractability, or Quadratic Residuosity intractabilty.

Most of these schemes share common features which make them leakage resilient. In previous models (which did not model side channels), public key cryptography was essentially based on having a public key $pk$ for which it is a hard problem to find the associated secret key $sk$.

In this model, the key idea is to have exponentially-many secret keys for each public key, and to ensure the following properties:
\begin{itemize}
\item All secret keys associated with a given public key can decrypt messages encrypted with that public key (correctness).
\item Given the public key and one associated secret key, finding another secret key associated with that public key is intractable.
\item Given the public key $pk$ and some fraction of the bits for an associated secret key $sk$, it is intractable to output the exact same secret key $sk$ with non-negligible probability.
\end{itemize}

The last two properties work together to provide security in the following way. Given bounded leakage about any single secret key does not give the adversary enough information to single out that particular secret key. Therefore, if the adversary does succeed, the adversary must with high probability output a different secret key associated to the same public key. In this case, the challenger and adversary have contradicted the second property listed above, that given one secret key, it is intractable to find another with the same associated public key.

\subsection{QR-based encryption scheme}

We an define a system that is resilient against secret key leaks using the quadratic residuosity problem. The encryption scheme is as follows:
\\

\textbf{Setup:} Choose a Blum integer $N$ such that no party knows the factorization. Let $\ell$ be a parameter for the amount of leakage.

\textbf{Key Generation:} Randomly sample  $sk = (s_0,\dots,s_\ell) \leftarrow \{0,1\}^\ell$. For $i \in [1,\ell]$, sample $g_i \leftarrow QR_N$. $pk = (g_1,\dots,g_\ell,h)$, where $h = \prod_{i=1}^\ell g_i^{-s_i}$.

\textbf{Encryption:} Randomly sample $r \leftarrow \mathbb{Z} \cap [0,N^2]$. For a message $m \in \bit$ and public key $(g_1,\dots,g_\ell,h)$, compute the ciphertext $c = (g_1^r,\dots,g_\ell^r,(-1)^m h^r)$. 

\textbf{Decryption:} Given the ciphertext $(c_1,\dots,c_\ell,c_0)$ and secret key $(s_1,\dots,s_\ell)$, compute $c_0 \prod_{i=1}^\ell c_i^{s_i}$. Return $0$ if this is $1$, or $1$ if this is $-1$.
\\

Note that we chose $r$ from a set of size $N^2$, not $N$. The reason for this is that ideally, we would choose $r$ from a set the same size as $QR_N$, but we can't compute $|QR_N|$ without the factorization of $N$. Choosing $r$ from a set of size $N^2$ gets us close enough.

The correctness of this scheme is fairly easy to see. The value we compute in decryption is exactly 
\begin{align*}
&(-1)^m h^r \prod_{i=1}^\ell g_i^{s_i r}
\\ = &(-1)^m \prod_{i=1}^\ell g_i^{s_i r - s_i r}
\\ = &(-1)^m.
\end{align*}

There are exponentially many secret keys which match the public key, for $\ell$ large enough. In fact, for the right choice of $\ell$, the $h$ will be very close to a uniform distribution over $QR_N$; this follows from the leftover hash lemma (which will be explained shortly). First, we recall the definition for a 2-universal hash function or pairwise hash function:

\begin{definition}
$H$ is a 2-universal hash function family for $\mathcal{X} \rightarrow \mathcal{Y}$ if $\forall x \neq x' \; \Pr_{h \leftarrow H}(h(x) = h(x')) = \frac{1}{|\mathcal{Y}|}$.
\end{definition}

The key here is that the hash function family $h_{g_1,\dots,g_\ell}(x) = \prod_{i=1}^\ell g_i ^ {x_i}$ is 2-universal. This follows from the fact that the $g_i$ are chosen uniformly at random from $QR_N$, so conditional on each possible choice of $x_i$s, their product must be uniform at random over $QR_N$, except for the degenerate case where all the $x_i$ are $0$. However, this cannot happen for both $x$ and $x'$ if $x \neq x'$.

\begin{lemma}[Leftover hash lemma]
If $H$ is a 2-universal hash family on $\mathcal{X} \leftarrow \mathcal{Y}$, then for any $x \in \mathcal{X}$,
\[
\delta(h \leftarrow H \then (h,h(\unif{\mathcal{X}})) \quad, \quad 
         (h \leftarrow H \then (h,\unif{\mathcal{Y}})) \le 2\sqrt{\frac{|\mathcal{Y}|}{|\mathcal{X}|}}.
\]
\end{lemma}

This tells us that for sufficiently large $\ell$, $(g_1,\dots,g_\ell,h) \approx_S (g_1,\dots,g_\ell,\unif{QR_N})$, where $h = \prod_{i=1}^\ell g_i^{-s_i}$ and each $g_i \sim \unif{QR_N}$ and $s_i \sim \unif{\bit}$.

\begin{definition}[Min-entropy]
For a random variable $X$, we can define its \emph{min-entropy} as 
\[
H_1(X) = -\log \max_x \Pr(X = x).
\]
We say a random source is a \emph{$k$-source} if $H_1(X) > k \iff \forall x \Pr(X = x) < 2^{-k}$.
\end{definition}

\begin{definition}
An \emph{extractor} is a function $\mathrm{Ext}(x,r)$, where $x$ comes from a $k$-source, $r$ is a string of $d$ random bits, and $\mathrm{Ext}(x,r)$ is a string of bits of length $\ell$ that is statistically indistinguishable from uniform.
\end{definition}

We can further refine the definition of an extractor to require it to output nearly uniform bits even when the random seed is exposed. The leftover hash lemma states that we can build these strong extractors out of 2-universal hash functions.


Now, because some part of the key will leak, we can view the secret key as a $(1-\varepsilon)n$-source, where leaking more bits of the secret key will result in worse bounds on the entropy. This QR-based encryption scheme can be viewed as encryption that uses a randomness extractor on the secret key and a random seed $r$: each encryption of a message is just $\mathrm{Enc}(pk,m) = \mathrm{Ext}(sk,r) \otimes m$. In our case, $r$ is the tuple $(g_1,\dots,g_\ell)$, and $\otimes$ is multiplication within the group $QR_N$. The random seed is part of the public key, but this is not a problem because our hash
function is a strong extractor. All schemes which we know of which are leakage-resilient make
use of extractors.

\section{Only computation leaks}

How can we compute privately in a setting where an eavesdropper can record any computations? One approach is to identify a small, simple function which, if computed on trusted hardware, would allow for carrying out the rest of the computation covertly. The model here is that an ordinary user of the computer can make use of this trusted component, but an adversary cannot. We would like that:
\begin{enumerate}
\item The amount of trusted computation is small.
\item An adversary cannot easily gain access to data from a trusted computation.
\item Without information from inside the trusted base, there is no way to recover the other intermediate stages of the program.
\end{enumerate}

The particular abstraction we want here is a \emph{one-time memory}.

\begin{definition}
A \emph{one-time memory} stores two values, $k_0$ and $k_1$. On input $b$, it outputs $k_b$ and deletes $k_{\neg b}$.
\end{definition}

The basic idea is that a one-time memory can stand in for oblivious transfer in our two-party computation protocol using Yao's garbled circuits (we refer back to previous notes on the details of circuit garbling). This gives us a one-time program which can be covertly executed on a specific input. The only thing an adversary can learn is the value of the output.

We can use OTMs and their resulting OTPs in the scenario of only computation leaks, where instead of deleting the other key we simply don't look at it. The computation only ever reads $k_b$, so no information is revealed to the adversary about the other value stored in memory. And there is no way for an adversary to learn about the unencrypted values by looking at their encrypted counterparts. Furthermore, even if the adversary is powerful enough to read both keys stored in the OTM, we can still have some defence against this by encrypting them with a leakage-resilient scheme such as the QR one just discussed.

However, OTMs have some serious drawbacks. If we want to compute many different functions, we will need to garble them and their inputs all offline, which means we can only do a bounded amount of online computation before having to go offline again.


% % % You should probably leave the below alone % % %
\nocite{*}
\bibliographystyle{alpha}
\bibliography{lect-24-scribe}
\end{document}
