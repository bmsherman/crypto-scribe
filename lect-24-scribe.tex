
\documentclass[10pt]{article}
\usepackage{amsfonts,amsthm,amsmath,amssymb}
\usepackage{array}
\usepackage{epsfig}
\usepackage[
  margin=1.5cm,
  includefoot,
  footskip=30pt,
]{geometry}

%%% YOUR NAMES GO HERE %%%
\newcommand{\scribes}{Eric Atkinson, Ben Sherman}
%%% LECTURE NUMBER %%%
\newcommand{\lecnumber}{24}
%%% TITLE OF THE LECTURE %%%
\newcommand{\lectitle}{Cryptography when secrecy is hard to find (leakage resistance)}
%%% DATE OF THE LECTURE %%%
\newcommand{\thedate}{May 4, 2016}

\newcommand{\bit}{\{0,1\}}
\newcommand{\unif}[1]{\mathcal{U}\left( #1 \right)}
\newcommand{\Prob}[1]{\text{Pr}\left[ {#1} \right]}
\newcommand{\given}{\ |\ }
\newcommand{\suchthat}{\given}
\newcommand{\nat}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bool}{\mathbb{B}}
\newcommand{\cat}{\ ||\ }
\newcommand{\then}{\ ;\ }

\begin{document}
\input{scribe-template-preamble.tex}

\handout{6.875J/18.425J Cryptography and Cryptanalysis}
{\thedate}
{Instructor: Shafi Goldwasser}
{Scribes: \scribes}
{Lecture \lecnumber: \lectitle}
{\lecnumber}

%%%% body goes in here %%%%
\section{Non-comprehensive Instructions}
\begin{itemize}
	\item Finish a first draft of the scribe notes by the day after lecture (i.e. Wednesday lecture $\rightarrow$ draft by Thursday night).
	\item Send us your source (.tex) files, and a compiled file as as a PDF. (By email: {\tt 6.875-ta-sp16@mit.edu})
\end{itemize}

\section{Side-channel attacks (introduction)}

So far in the class, the cryptographic protocols and constructions that we have considered have used the following assumptions:
\begin{itemize}
\item Algorithms are public.
\item Private keys are perfectly secret and random.
\item Cryptographic computations are opaque to an adversary.
\end{itemize}

These common assumptions provide a rich theory based on reductionist security proofs from computational assumptions to secure primitives. And so far in this class, we have explored a variety of computational notions within this framework, and found some surprising abilities (such as public key cryptography, homomorphic encryption, etc.).

For instance, a secret key that is stored on one's computer cannot be observed by an adversary. However, the above assumptions do not hold in many real-life settings, because computations ``leak.''

When computations run on a computer, they consume power, and emit noise as well as radiation. If there's someone who can measure how much time the computation takes, how much heat the computer generates (such as by detecting changes in temperature in the nearby environment), this can give you information about the secret keys. 

It's possible to translate physical observations into attacks on the security of cryptographic schemes. Our proofs in the class so far have not taken into account these considerations. Attacks include:

\begin{itemize}
\item \emph{Cold boot attacks} are attacks on computers which are not running. If a computer is inspected not longer after it is shut off, the memory may still retain information, and so it is possible to recover secret keys.
\item Garfinkle \cite{garfinkel2003} looked at \emph{erased hard disks} and was able to recover lots of forensic information.
\item \emph{Shared sources of randomness}: Often, there is reuse of secret keys across different cryptographic applications. Using access to many cryptographic public keys, where the private keys are correlated with each other (due to a shared source of randomness), it may be possible to defeat cryptographic security.
\item \emph{Timing attacks} glean information by measuring how much time a computation takes. For instance, one can, by observing how much time an RSA signing scheme takes, learn about the RSA exponent (given that signing is performed via repeated squaring with the exponent, and some exponents will take longer than others).
\item \emph{Power consumption attacks} measure the power consumed while performing cryptographic operations.
\end{itemize}

There are countermeasures meant to prevent side-channel attacks such as those listed above. There are both hardware and software countermeasures. In hardware, it is possible to shield components to make it difficult to measure the emission of radiation or heat. In software, it is possible to try to fix the timing of cryptographic operations, to use oblivious RAM, and to use various other heuristics to prevent leakage of information through side-channels.

Can we use more \emph{theory} at design time to battle reality? Can we do cryptography assuming \emph{no} secrecy? Maybe we don't need secret keys at all. Maybe everything can be public, and we can still do public key encryption, secure computation, and so on. \emph{Obfuscation} attempts to answer this question. In this lecture, we can't do away with all secrecy, but can reduce the amount of secrecy required.

Approaching side-channel attacks from a theoretical angle, we explicitly model side-channel attacks. We can then try to build modified schemes which are secure with respect to this model, and even try to construct general compilers for protocols secure against these models from protocols which are secure under classical cryptographic assumptions.

Work modeling side-channel attacks is highly technical, so this lecture provides only a glimpse. So far, the results have questionable benefit. Schemes often only provide security against a fixed fraction of leakage. So a scheme may be secure against leaking 90\% of the secret key, but to be secure against 95\% leakage, a completely different scheme may be required.

We now present a mathematical model side-channel attacks (computation time, power, etc.). Later, we will discuss the addition of secure hardware assumptions to cryptographic assumptions. The goal will be to use the same computational assumptions as before, and to minimize the use of secure hardware.

There are a variety of ways to model side-channel attacks. All of the models generally maintain the notion of a PPT adversary $A$. In addition to $A$'s computational abilities, $A$ is allowed to make measurements $L(\cdot)$ on the internal state of a computation. Models differ in what restrictions are imposed on the measurement function $L$:

\begin{itemize}
\item What does $L$ really have access to? Possible choices include the entire state of the computation, or only a certain amount of internal state, or perhaps only contents of the cache. In the \emph{memory leakage} (ML) class of models, we have \emph{global measurements}, where $L$ applies to the entire memory. In contrast, with the \emph{only computation} (OC) class of models, we have only \emph{local measurements}, so $L$ can only be applied to memory that is being used in the current computation step.
\item What complexity class does $L$ come from? $L$ may be required to be a polynomial-time algorithm or representable by a ``low-depth'' circuit.
\item How many measurements can $L$ make? In \emph{bounded leakage} models, it can only measure once, or a limited number of times. In \emph{continual leakage} models, there is no bound on the number of times that measurements can be made. However, it is possible to prevent information leakage by erasing memory contents. For instance, a scheme secure against a continual leakage model might use the same public key, but keep changing secret keys, and erasing previous ones, so that an adversary cannot fully determine a single secret key.
\item When is $L$ chosen? Before or after the public key is chosen?
\item Is there noise in the measurement of $L$? For instance, it could be modeled as a random variable which is only biased towards the actual internal state.
\end{itemize}

\section{Bounded memory leakage (ML)}

How to design public key encryption where someone can measure the secret key a bounded number of times?

Memory retains its content after power is lost. Contents in RAM decay slowly; last for several minutes.

Can recover ``noisy''' keys. Say you're using RSA, and you have stored in memory the decryption exponent $d$ (where $d e = 1 \mod \varphi(n)$). You can' see $d$ exactly, but can see a noisy version of $d$. We want to deal with this kind of attack.

Update the notion of semantic security to take into account the adversary's new capabilities. We're going to change it as follows: There is semantic security against a $\lambda$-memory attack if for any leakage function $L(\cdot)$, the adversary can't find $m_0$ and $m_1$ that can distinguish between the encryptions.

The restriction is that $L : SK \to \bit^n$ such that $n = |L(SK)| < \lambda(|SK|)$. This forces that there is some entropy left in the secret key. In fact, this is just a strong as simply requiring that there is some entropy left in the secret key.

RSA variants: RSA is insecure theoretically with 50\% leakage, practically it was insecure with 25\% leakage?

Can we do it with an arbitrarily large fraction of leakage?

General randomized encoding of secret key: increases length of storage, decreases efficiency.

Public key encryption secure against memory leakage attacks.

\begin{theorem}
For every $\varepsilon > 0$, there exists a public key encryption scheme that can tolerate $\lambda = (1 - \varepsilon)n$ leakage attacks.
\end{theorem}
They use either lattice problems, Diffie-Hellman decisional intractability, or Quadratic Residuosity intractabilty.

What makes these schemes leakage resilient?

Let's imagine what a proof of security could look like. Old proofs of security: suppose we have a PK encryption scheme based on some hard problem. Suppose there's a leakage adversary, we want to show that we can solve the problem.

Start with a public key $pk$ for which it is a hard problem to find the secret key $sk$.

Adversary            Challenger
<- PK
-> L
<- L(SK)
-> ($m_0, m_1$)
Challenger flips random bit $b$
<- Enc($m_b$)
-> b'
Does (b == b')?

New paradigm: Instead of having one secret key, we will have one public key, and many secret keys for a single public key. Why is this helpful? Suppose that we did have this property. Exponentially many secret keys for a given single public key. Correctness: All of the secret keys can decrypt correctly. But, want to make it so that given one secret key, it should be hard computationally to find any other secret key.

Giving bounded leakage about any single secret key is not enough to point to it, so adversary with likely output another one. Then, if the adversary does succeed, he almost surely successfully outputs a different secret key from the one which the challenger does not already know, and so together they have solved the computationally hard problem of finding another secret key from one given secret key.

If an adversary could find a secret key, then we violate

\section{QR-based encryption scheme}


\textbf{Setup:} Choose a Blum integer $N$ such that no party knows the factorization. Let $\ell$ be a parameter for the amount of leakage.

\textbf{Key Generation:} Randomly sample  $sk = (s_0,\dots,s_\ell) \leftarrow \{0,1\}^\ell$. For $i \in [1,\ell]$, sample $g_i \leftarrow QR_N$. $pk = (g_1,\dots,g_\ell,h)$, where $h = \prod_{i=1}^\ell g_i^{-s_i}$.

\textbf{Encryption:} Randomly sample $r \leftarrow \mathbb{Z} \cap [0,N^2]$. For a message $m \in \{0,1\}$ and public key $(g_1,\dots,g_\ell,h)$, compute the ciphertext $c = (g_1^r,\dots,g_\ell^r,(-1)^m h^r)$. 

\textbf{Decryption:} Given the ciphertext $(c_1,\dots,c_\ell,c_0)$ and secret key $(s_1,\dots,s_\ell)$, compute $m = c_0 \prod_{i=1}^\ell c_i^{s_i}$.

Note that we chose $r$ from a set of size $N^2$, not $N$. The reason for this is ideally we would choose $r$ from a set the same size as $QR_N$, but we can't compute $|QR_N|$ without the factorization of $N$. Choosing $r$ from a set of size $N^2$ gets us close enough.

\textbf{Remark 1:} There are exponentially many secret keys which match the public key, for $\ell$ large enough. In fact, for the right choice of $\ell$, the $h$ will be very close to a uniform distribution; this follows from the leftover hash lemma. 

\begin{definition}
$H$ is a 2-universal hash family for $\mathcal{X} \rightarrow \mathcal{Y}$ if $\forall x,y \; \Pr_{h \leftarrow H}(h(x) = h(y)) = \frac{1}{|\mathcal{Y}|}$.
\end{definition}

\begin{lemma}
The leftover hash lemma. If $H$ is a 2-universal hash family on $\mathcal{X} \leftarrow \mathcal{Y}$, then for any $x \in \mathcal{X}$, $\mathcal{L} \in \mathcal{X} \rightarrow \mathcal{Y}$, $(h,h(x),L(x)) \approx (h,y,L(x))$, where $h \leftarrow H$ and $y \leftarrow \mathcal{Y}$.
\end{lemma}

The claim here is that the hash function family $h_{g_1,\dots,g_\ell}(x) = \prod_{i=1}^\ell g_i ^ {x_i}$ is 2-universal. This tells us that for sufficiently large $\ell$, $(g_1,\dots,g_\ell,h) \approx (g_1,\dots,g_\ell,U)$.

\begin{definition}
Min-entropy. For a probability distribution $X$, we can define the min-entropy as $H_1(X) = -\log \max_x \Pr(X = x)$. We say a random source is a $k$-source if $H_1(X) > k \iff \forall x \Pr(X = x) < 2^{-k}$.
\end{definition}

\begin{definition}
An extractor is a function $\mathrm{Ext}(x,r)$, where $x$ comes from a $k$-source, $r$ is a string of $d$ random bits, and $\mathrm{Ext}(x,r)$ is a string of bits of length $\ell$ that is indistinguishable from uniform.
\end{definition}

We can futher refine the definition of an extractor to require it to output nearly uniform bits even when the random seed is exposed. The leftover hash lemma states that we can build these strong extractors out of 2-universal hash functions.

\textbf{Remark 2:} We can view the secret key as an entropy source, where leaking more bits of the secret key will result in worse bounds on the entropy. We can then design our encryption algorithm to act as a randomness extractor from the secret key and a random seed $r$: $\mathrm{Enc} = \mathrm{Ext}(sk,r) \oplus m$. In our case, $h^r = \prod_{i=1}^\ell g_i^{s_i r}$ serves as the extractor, so $h^r$ is indistinguishable from uniform. All schemes which we know which are leakage-resilient make
use of extractors.

\section{Part 2: Only computation leaks}

Want to identify a component $H$ that computes some elementary function, where we can implement any cryptographic algorithm securely when the adversary can run side channel attacks on the entire computation except for $H$. In fact we want more. Even, we can say we let the adversary run the entire executions himself, except for $H$.

$H$ should be some universal component that can be plugged in to any algorithm. Also it should be simple.

This idea of $H$ also comes up in one-time programs. One-time programs are programs $P$ which can be run on a single input, but after it has been run once, it cannot be run again (particularly, can't be run on another input).

Problem: Hardware is not a black box.

We want this little box $H$ that does not leak to do very little computation (as little as possible). Rewrite programs in such a way such that we use $H$ as little as possible (ideally, we would not even need $H$ at all!)

What is $H$? $H$ is a one-time memory unit (OTM). $H$ has two pieces of information in it: $k_0$ and $k_1$. It allows you to read one key, but then will erase the other key. Therefore, no computation is ever done on the key which is erased.

\begin{theorem}
(Under fully homomorphic encryption) Can compile any $f$ into one-time programs for $f$ where program = software + $H$. Use Yao's garbled circuits, and for every input wire, we will use OTMs to store the keys.
\end{theorem}

In the context of leakage resilient, one-time programs enable executions of any cryptographic functionality such that the adversary learns nothing but the output even if all secrets that are computed on are fully leaked.

Turn executions of cryptographic algorithms into OTPs (one time programs). If we had a computation we want to run many times, even if someone is watching, I can prepare in advance representations of the computation, such that I can compute them online later on (analogy to the one time pad). E.G., if we want to be able to sign 100 messages in the presence of computation leaks, can prepare 100 OTPs in advance to accomplish this.

In leakage resilience setting, we don't need secure hardware. And we don't want to have to prepare things in advance. Can we prepare work in a bounded amount of time, and later execute an unbounded amount of executions?

The answer is that we have made some progress. Suppose we take the $H$ OTM memory cells, and we can encrypt their contents. We have garbled circuits, with the keys encrypted on the OTMs. Depending on whether the bit is $0, 1$, we take one of the keys from the OTM. Now when we need to decrypt the key from the OTM, we now need a secure leakage-resilient encryption algorithm for encrypting the keys that we put on the OTM.

But in the first part of the talk, we only did it a bounded number of times, and here we would need unbounded.


% % % You should probably leave the below alone % % %
\nocite{*}
\bibliographystyle{alpha}
\bibliography{lect-24-scribe}
\end{document}
