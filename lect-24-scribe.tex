
\documentclass[10pt]{article}
\usepackage{amsfonts,amsthm,amsmath,amssymb}
\usepackage{array}
\usepackage{epsfig}
\usepackage[
  margin=1.5cm,
  includefoot,
  footskip=30pt,
]{geometry}

%%% YOUR NAMES GO HERE %%%
\newcommand{\scribes}{Eric Atkinson, Ben Sherman}
%%% LECTURE NUMBER %%%
\newcommand{\lecnumber}{24}
%%% TITLE OF THE LECTURE %%%
\newcommand{\lectitle}{Cryptography when secrecy is hard to find (leakage resistance)}
%%% DATE OF THE LECTURE %%%
\newcommand{\thedate}{May 4, 2016}

\newcommand{\bit}{\{0,1\}}
\newcommand{\unif}[1]{\mathcal{U}\left( #1 \right)}
\newcommand{\Prob}[1]{\text{Pr}\left[ {#1} \right]}
\newcommand{\given}{\ |\ }
\newcommand{\suchthat}{\given}
\newcommand{\nat}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bool}{\mathbb{B}}
\newcommand{\cat}{\ ||\ }
\newcommand{\then}{\ ;\ }
\newcommand{\keys}{\mathcal{K}}

\begin{document}
\input{scribe-template-preamble.tex}

\handout{6.875J/18.425J Cryptography and Cryptanalysis}
{\thedate}
{Instructor: Shafi Goldwasser}
{Scribes: \scribes}
{Lecture \lecnumber: \lectitle}
{\lecnumber}

%%%% body goes in here %%%%
\section{Non-comprehensive Instructions}
\begin{itemize}
	\item Finish a first draft of the scribe notes by the day after lecture (i.e. Wednesday lecture $\rightarrow$ draft by Thursday night).
	\item Send us your source (.tex) files, and a compiled file as as a PDF. (By email: {\tt 6.875-ta-sp16@mit.edu})
\end{itemize}

\section{Side-channel attacks (introduction)}

So far in the class, the cryptographic protocols and constructions that we have considered have used the following assumptions:
\begin{itemize}
\item Algorithms are public.
\item Private keys are perfectly secret and random.
\item Cryptographic computations are opaque to an adversary.
\end{itemize}

These common assumptions provide a rich theory based on reductionist security proofs from computational assumptions to secure primitives. And so far in this class, we have explored a variety of computational notions within this framework, and found some surprising abilities (such as public key cryptography, homomorphic encryption, etc.).

For instance, a secret key that is stored on one's computer cannot be observed by an adversary. However, the above assumptions do not hold in many real-life settings, because computations ``leak.''

When computations run on a computer, they consume power, and emit noise as well as radiation. If there's someone who can measure how much time the computation takes, how much heat the computer generates (such as by detecting changes in temperature in the nearby environment), this can give you information about the secret keys. 

It's possible to translate physical observations into attacks on the security of cryptographic schemes. Our proofs in the class so far have not taken into account these considerations. Attacks include:

\begin{itemize}
\item \emph{Cold boot attacks} are attacks on computers which are not running. If a computer is inspected not longer after it is shut off, the memory may still retain information, and so it is possible to recover secret keys. Contents in RAM decay slowly after losing power, and may last for several minutes.
\item Garfinkle \cite{garfinkel2003} looked at \emph{erased hard disks} and was able to recover lots of forensic information.
\item \emph{Shared sources of randomness}: Often, there is reuse of secret keys across different cryptographic applications. Using access to many cryptographic public keys, where the private keys are correlated with each other (due to a shared source of randomness), it may be possible to defeat cryptographic security.
\item \emph{Timing attacks} glean information by measuring how much time a computation takes. For instance, one can, by observing how much time an RSA signing scheme takes, learn about the RSA exponent (given that signing is performed via repeated squaring with the exponent, and some exponents will take longer than others).
\item \emph{Power consumption attacks} measure the power consumed while performing cryptographic operations.
\end{itemize}

There are countermeasures meant to prevent side-channel attacks such as those listed above. There are both hardware and software countermeasures. In hardware, it is possible to shield components to make it difficult to measure the emission of radiation or heat. In software, it is possible to try to fix the timing of cryptographic operations, to use oblivious RAM, and to use various other heuristics to prevent leakage of information through side-channels.

Can we use more \emph{theory} at design time to battle reality? Can we do cryptography assuming \emph{no} secrecy? Maybe we don't need secret keys at all. Maybe everything can be public, and we can still do public key encryption, secure computation, and so on. \emph{Obfuscation} attempts to answer this question. In this lecture, we can't do away with all secrecy, but can reduce the amount of secrecy required.

Approaching side-channel attacks from a theoretical angle, we explicitly model side-channel attacks. We can then try to build modified schemes which are secure with respect to this model, and even try to construct general compilers for protocols secure against these models from protocols which are secure under classical cryptographic assumptions.

Work modeling side-channel attacks is highly technical, so this lecture provides only a glimpse. So far, the results have questionable benefit. Schemes often only provide security against a fixed fraction of leakage. So a scheme may be secure against leaking 90\% of the secret key, but to be secure against 95\% leakage, a completely different scheme may be required.

We now present a mathematical model side-channel attacks (computation time, power, etc.). Later, we will discuss the addition of secure hardware assumptions to cryptographic assumptions. The goal will be to use the same computational assumptions as before, and to minimize the use of secure hardware.

There are a variety of ways to model side-channel attacks. All of the models generally maintain the notion of a PPT adversary $A$. In addition to $A$'s computational abilities, $A$ is allowed to make measurements $L(\cdot)$ on the internal state of a computation. Models differ in what restrictions are imposed on the measurement function $L$:

\begin{itemize}
\item What does $L$ really have access to? Possible choices include the entire state of the computation, or only a certain amount of internal state, or perhaps only contents of the cache. In the \emph{memory leakage} (ML) class of models, we have \emph{global measurements}, where $L$ applies to the entire memory. In contrast, with the \emph{only computation} (OC) class of models, we have only \emph{local measurements}, so $L$ can only be applied to memory that is being used in the current computation step.
\item What complexity class does $L$ come from? $L$ may be required to be a polynomial-time algorithm or representable by a ``low-depth'' circuit.
\item How many measurements can $L$ make? In \emph{bounded leakage} models, it can only measure once, or a limited number of times. In \emph{continual leakage} models, there is no bound on the number of times that measurements can be made. However, it is possible to prevent information leakage by erasing memory contents. For instance, a scheme secure against a continual leakage model might use the same public key, but keep changing secret keys, and erasing previous ones, so that an adversary cannot fully determine a single secret key.
\item When is $L$ chosen? Before or after the public key is chosen?
\item Is there noise in the measurement of $L$? For instance, it could be modeled as a random variable which is only biased towards the actual internal state.
\end{itemize}

\section{Bounded memory leakage (ML)}

In this seection, we will consider how to design a public key encryption scheme which is secure with respect to the bounded memory leakage (ML) model, where the adversary can make partial measurements a bounded number of times.

The idea in this model is that the adversary can recover ``noisy''' keys. Suppose you're using RSA, and you have stored in memory the decryption exponent $d$ (where $d e = 1 \mod \varphi(n)$). The adversary can't see $d$ exactly, but can see a noisy version of $d$. 

We update the notion of semantic security to take into account the adversary's new capabilities. We're going to change it as follows: There is semantic security against a $\lambda$-memory attack if for any leakage function $L(\cdot)$, the adversary can't find $m_0$ and $m_1$ that can distinguish between the encryptions.

Let $\keys_S$ be the set of private keys. We require for the measurement function $L : \keys_S \to \bit^n$ can only determine a fraction $\lambda$ of the bits, that is, $n \le \lambda \lg |\keys_S|$, or if the space of private keys is bitvectors of length $n_{SK}$, i.e., $\keys_S = \bit^{n_{SK}}$, then $n \le \lambda n_{SK}$. This means that it is impossible for $L$ to uniquely determine the secret key. In fact, this requirement is just as strong as the requirement that there must be some entropy remaining in the secret key when conditioned on the observation of $L$.

Most contemporary protocols are not very secure with respect to this model. RSA is theoretically secure with up to 50\% leakage, but practically found insecure with as little as 25\% leakage. AES is insecure against 85\% leakage.

Is it possible to create public key encryption secure against memory leakage attacks with an arbitrarily large fraction of leakage? Yes, it is:

\begin{theorem}
For every $\varepsilon > 0$, there exists a public key encryption scheme that can tolerate $\lambda = (1 - \varepsilon)n$ leakage attacks.
\end{theorem}
They use either lattice problems, Diffie-Hellman decisional intractability, or Quadratic Residuosity intractabilty.

What makes these schemes leakage resilient?

Let's imagine what a proof of security could look like. Old proofs of security: suppose we have a PK encryption scheme based on some hard problem. Suppose there's a leakage adversary, we want to show that we can solve the problem.

Start with a public key $pk$ for which it is a hard problem to find the secret key $sk$.

Adversary            Challenger
<- PK
-> L
<- L(SK)
-> ($m_0, m_1$)
Challenger flips random bit $b$
<- Enc($m_b$)
-> b'
Does (b == b')?

New paradigm: Instead of having one secret key, we will have one public key, and many secret keys for a single public key. Why is this helpful? Suppose that we did have this property. Exponentially many secret keys for a given single public key. Correctness: All of the secret keys can decrypt correctly. But, want to make it so that given one secret key, it should be hard computationally to find any other secret key.

Giving bounded leakage about any single secret key is not enough to point to it, so adversary with likely output another one. Then, if the adversary does succeed, he almost surely successfully outputs a different secret key from the one which the challenger does not already know, and so together they have solved the computationally hard problem of finding another secret key from one given secret key.

If an adversary could find a secret key, then we violate

\section{QR-based encryption scheme}


\textbf{Setup:} Choose a Blum integer $N$ such that no party knows the factorization. Let $\ell$ be a parameter for the amount of leakage.

\textbf{Key Generation:} Randomly sample  $sk = (s_0,\dots,s_\ell) \leftarrow \{0,1\}^\ell$. For $i \in [1,\ell]$, sample $g_i \leftarrow QR_N$. $pk = (g_1,\dots,g_\ell,h)$, where $h = \prod_{i=1}^\ell g_i^{-s_i}$.

\textbf{Encryption:} Randomly sample $r \leftarrow \mathbb{Z} \cap [0,N^2]$. For a message $m \in \{0,1\}$ and public key $(g_1,\dots,g_\ell,h)$, compute the ciphertext $c = (g_1^r,\dots,g_\ell^r,(-1)^m h^r)$. 

\textbf{Decryption:} Given the ciphertext $(c_1,\dots,c_\ell,c_0)$ and secret key $(s_1,\dots,s_\ell)$, compute $m = c_0 \prod_{i=1}^\ell c_i^{s_i}$.

Note that we chose $r$ from a set of size $N^2$, not $N$. The reason for this is ideally we would choose $r$ from a set the same size as $QR_N$, but we can't compute $|QR_N|$ without the factorization of $N$. Choosing $r$ from a set of size $N^2$ gets us close enough.

\textbf{Remark 1:} There are exponentially many secret keys which match the public key, for $\ell$ large enough. In fact, for the right choice of $\ell$, the $h$ will be very close to a uniform distribution; this follows from the leftover hash lemma. 

\begin{definition}
$H$ is a 2-universal hash family for $\mathcal{X} \rightarrow \mathcal{Y}$ if $\forall x,y \; \Pr_{h \leftarrow H}(h(x) = h(y)) = \frac{1}{|\mathcal{Y}|}$.
\end{definition}

\begin{lemma}
The leftover hash lemma. If $H$ is a 2-universal hash family on $\mathcal{X} \leftarrow \mathcal{Y}$, then for any $x \in \mathcal{X}$, $\mathcal{L} \in \mathcal{X} \rightarrow \mathcal{Y}$, $(h,h(x),L(x)) \approx (h,y,L(x))$, where $h \leftarrow H$ and $y \leftarrow \mathcal{Y}$.
\end{lemma}

The claim here is that the hash function family $h_{g_1,\dots,g_\ell}(x) = \prod_{i=1}^\ell g_i ^ {x_i}$ is 2-universal. This tells us that for sufficiently large $\ell$, $(g_1,\dots,g_\ell,h) \approx (g_1,\dots,g_\ell,U)$.

\begin{definition}
Min-entropy. For a probability distribution $X$, we can define the min-entropy as $H_1(X) = -\log \max_x \Pr(X = x)$. We say a random source is a $k$-source if $H_1(X) > k \iff \forall x \Pr(X = x) < 2^{-k}$.
\end{definition}

\begin{definition}
An extractor is a function $\mathrm{Ext}(x,r)$, where $x$ comes from a $k$-source, $r$ is a string of $d$ random bits, and $\mathrm{Ext}(x,r)$ is a string of bits of length $\ell$ that is indistinguishable from uniform.
\end{definition}

We can futher refine the definition of an extractor to require it to output nearly uniform bits even when the random seed is exposed. The leftover hash lemma states that we can build these strong extractors out of 2-universal hash functions.

\textbf{Remark 2:} We can view the secret key as an entropy source, where leaking more bits of the secret key will result in worse bounds on the entropy. We can then design our encryption algorithm to act as a randomness extractor from the secret key and a random seed $r$: $\mathrm{Enc} = \mathrm{Ext}(sk,r) \oplus m$. In our case, $h^r = \prod_{i=1}^\ell g_i^{s_i r}$ serves as the extractor, so $h^r$ is indistinguishable from uniform. All schemes which we know which are leakage-resilient make
use of extractors.

\section{Part 2: Only computation leaks}

How can we compute privately in a setting where an eavesdropper can record any computations? One approach is to identify a small, simple function which, if computed on trusted hardware, would allow for carrying out the computation covertly. The particular abstraction we want is a \emph{one-time memory}.

\begin{definition}
A one-time memory stores two values $k_0$ and $k_1$. On input $b$, it outputs $k_b$ and deletes $k_{\neg b}$.
\end{definition}

The basic idea is that a one-time memory can stand in for oblivious transfer in our two-party computation protocol using Yao's garbled circuits (we refer back to previous notes on the details of circuit garbling). A nice feature of OTM is that for only computation leaks, we don't need any specialized hardware given fully homomorphic encryption. The computation only ever reads $k_b$, so no information is revealed about the other value stored in memory. And given the security properties of
FHE, there is no way for an adversary to learn about the unencrypted values by looking at their encrypted counterparts. Furthermore, even if the adversary is powerful enough to read both keys stored in the OTM, we can still have some defence against this by encrypting them with a leakage-resilient scheme such as the QR one just discussed.

However, OTMs have some serious drawbacks. If we want to compute $N$ different functions, we will need to garble them all offline, which means we can only do a bounded amount of online computation before having to go offline again.


% % % You should probably leave the below alone % % %
\nocite{*}
\bibliographystyle{alpha}
\bibliography{lect-24-scribe}
\end{document}
